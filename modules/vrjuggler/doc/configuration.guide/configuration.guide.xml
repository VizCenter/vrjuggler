<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN"
"http://www.oasis-open.org/docbook/xml/4.1.2/docbookx.dtd">
<book>
  <bookinfo>
    <title>VR Juggler</title>

    <subtitle>Configuration Guide</subtitle>

    <releaseinfo>Version 2.0 Alpha 1</releaseinfo>

    <pubdate>$Date$</pubdate>
  </bookinfo>

  <preface>
    <title>Preface</title>

    <para>This book describes how to create configuration files for VR
    Juggler. It discusses many of the details of configuring a VR System from
    scratch.</para>

    <para>This book assumes that the user has read the VR Juggler Getting
    Started Guide. The VRJConfig User&#39;s Guide may also prove helpful.</para>
  </preface>

  <chapter>
    <title>Introduction</title>

    <para>Configuring software for an immersive VR system can be a difficult
    and time consuming process. This is largely because of the size and
    complexity of the hardware components that make up the system - there may
    be multiple displays and a multitude of input devices. Furthermore, many
    systems are unique, or at least highly customized.</para>

    <para>VR Juggler attempts to make the configuration process as simple as
    possible. It includes a GUI application called VRJConfig to edit config
    files. Use of the GUI has many advantages: it can provide an organized
    view of the configuration information, with help information or suggested
    values readily available. It can prevent many simple mistakes (such as
    typos in text-based configuration files) and help resolve others.</para>

    <para>In addition to this, the VR Juggler config files themselves are
    well-structured, allowing the configurations of various elements of the VR
    system to be created separately and then combined in various ways.</para>

    <section>
      <title>An Overview of VR Juggler Configuration</title>

      <para>VR Juggler&#39;s configuration files are composed of a collection
      of &#34;configuration elements.&#34; Each configuration element contains
      the information to configure a single component of VR Juggler. These
      components might be display windows, device drivers, or even
      applications. Naturally, each configuration element contains vastly
      customized information for the component it represents. It is the
      combination of a set of configuration elements and the way they work
      together that makes up each unique VR Juggler configuration.</para>

      <para>All configuration elements have individual names, so that multiple
      elements for the same kind of component can be distinguished. This
      means, for example, that a VR Juggler configuration can include several
      display windows with separate screen coordinates and viewing parameters,
      each with a unique name. It also means that VR Juggler can use an
      arbitrary number and variety of displays or devices at any time, limited
      only by the capabilities of the underlying hardware.</para>

      <para>VRJConfig represents configuration files as a set of categorized
      configuration elements as seen in <xref linkend="VRJConfigMain" />.
      VRJConfig allows you to view multiple configurations side-by-side making
      it easy to copy configuration elements from one configuration to
      another.</para>

      <figure id="VRJConfigMain">
        <title>Editing configurations with VRJConfig.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures/mainpanel.png" format="PNG" scale="50"
            width="4in" />
          </imageobject>
        </mediaobject>
      </figure>
    </section>
  </chapter>

  <chapter>
    <title>Building a Configuration File from Scratch</title>

    <para>VR Juggler includes a number of sample configuration files for
    common VR systems. These files are based on the systems readily available
    to the VR Juggler developers and our contributors, but obviously we cannot
    provide a comprehensive set of example configurations - the field is
    simply too diverse.</para>

    <para>In this section we will demonstrate how to create a VR Juggler
    configuration file from scratch, describing each element and suggesting an
    order of steps to setup a new VR system in the easiest possible way. Our
    example system will be a four-walled projection system similar to Iowa
    State University&#39;s C4 device. After the step-by-step example, we will
    also briefly describe major variations, such as the differences necessary
    to create a configuration for a Head-Mounted Display, and some specific
    examples of setting up various input devices.</para>

    <section>
      <title>Before You Start: Collecting Information</title>

      <para>Configuring a VR system is much easier if all the necessary
      information is readily at hand. Sometimes, though, it can be hard to
      figure out exactly what is needed. The following non-exhaustive list
      suggests some of the data that it may be helpful to collect:</para>

      <itemizedlist>
        <listitem>
          <para><subscript><emphasis>Display Information.</emphasis></subscript></para>

          <para><subscript>This includes knowing where your displays are in
          space. In projection-based VR systems, this will include the
          positions of each screen. For a head-mounted display, it would be
          the positions and sizes of the display surfaces relative to the
          positions of the users&#39; eyes. This also includes knowing how the
          displays of the host computer map to the displays of the VR system -
          for example, the position and size of a graphics window needed to
          drive a given VR display.</subscript></para>
        </listitem>

        <listitem>
          <para><emphasis>Input Device Information:</emphasis></para>

          <para>This includes knowing what input devices you intend to use and
          how they are connected to the host computer. For some devices, this
          will be a serial port name and baud rate, for others it might be a
          network address and port number. Tracking systems, in particular,
          tend to have a large number of device-specific configuration
          options. For any tracking system, you will need to know the
          coordinate system its data uses.</para>
        </listitem>

        <listitem>
          <para><emphasis>Alternate configurations:</emphasis></para>

          <para>Some VR systems can be used in a variety of ways. For example,
          you might have a desk with a movable display surface, or you may
          need to choose between mono and stereo display modes, or you may
          have a head-mounted display that supports multiple video aspect
          ratios. Since VR Juggler applications can load multiple
          configuration files, it may be helpful to create a &#34;base&#34;
          config file with the information that never changes, as well as
          several additional helper files that describe the components of the
          system that may be reconfigurable.</para>
        </listitem>

        <listitem>
          <para><emphasis>VRJConfig usage information.</emphasis></para>

          <para>The VRJConfig program used to edit configuration files has
          many powerful capabilities. While it is designed to be easy to learn
          and use, it may be helpful to browse the <citetitle>VRJConfig
          User&#39;s Guide</citetitle>. The information in the Guide is also
          available via VRJConfig&#39;s <guimenu>help</guimenu> menu.</para>
        </listitem>
      </itemizedlist>
    </section>

    <section>
      <title>Create a New Configuration File</title>

      <para>Many of the sample configuration files included with VR Juggler
      are modular - that is, different parts of the system are described in
      different files, and multiple files are loaded to configure the entire
      VR system. To simplify this example, we&#39;ll put all of our
      configuration information into a single file.</para>

      <para>First, start VRJConfig and click on the <guibutton>New</guibutton>
      button to create a new file. Choose a name and directory for the file
      you want to create. For this tutorial, you can ignore the included files
      list.</para>
    </section>

    <section>
      <title>Decide on the Origin</title>

      <para>All displays and input data in VR Juggler are specified relative
      to a single origin point. The origin is some point in the physical space
      inside or around the VR System. Before we configure anything else, we
      have to decide where that point will be.</para>

      <para>For a Surround-Screen VR (<acronym>SSVR</acronym>) system, we
      decided that the origin point would be the center of the floor,
      equidistant from each wall. This is a common convention and is usually
      very convenient.</para>

      <para>We also need to define the orientation of our origin. Again there
      is a common convention which we recommend. We use a right-handed
      coordinate system, with positive X to the right of an observer looking
      toward the front screen. Positive Y is up and positive Z is toward the
      rear of the system (away from the front screen).</para>

      <para>Note that in the sample VR Juggler configuration files, all
      positions related to displays or input devices are given in meters.</para>
    </section>

    <section id="BasicTrackerConfig">
      <title>Configure Trackers</title>

      <para>The easiest place to start is at the bottom, with input hardware.
      Click the <guibutton>New Config Element</guibutton> button and you will
      be presented with a list of all the possible configuration elements you
      can make. For this example, we will use an Ascension MotionStar for our
      tracking system. Choose the <guibutton>MotionStar</guibutton> element in
      the list and click <guibutton>OK</guibutton>. A new configuration
      element for a MotionStar device is added to your configuration.</para>

      <para>Now we need to edit the MotionStar configuration to describe the
      details of our system. Selecting the newly-created MotionStar
      configuration element will bring up an editor for your MotionStar device
      as seen in <xref linkend="MotionStarEditor" />.</para>

      <figure id="MotionStarEditor">
        <title>Editing the MotionStar input driver.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures/motionstar_chunk.png" format="PNG"
            scale="45" width="4in" />
          </imageobject>
        </mediaobject>
      </figure>

      <para>The MotionStar is a separate computer that sits on a network and
      provides position data to other interested hosts. So it should not be
      surprising that the first few properties in the configuration are
      networking settings - IP address and port of the MotionStar, for
      example. Other input devices may use other communications methods, such
      as a serial connection. In that case, the configuration for that device
      would include port name and baud rate settings instead of the networking
      settings.</para>

      <note>
        <para>Please refer to the section below for configuring transformation
        settings for the tracking system.</para>
      </note>

      <para>Most of the other configuration options shown for the MotionStar
      are particular to its specific hardware and low-level software driver,
      and are described by the device&#39;s own documentation. However, we
      should draw attention to the <property>Number of Birds</property>
      property. The MotionStar hardware supports multiple positional sensors,
      called birds. In our example setup, we have two sensors. One is attached
      to a pair of stereo glasses, and the other is mounted to the wand which
      enables users to interact with the virtual environment.</para>

      <para>Note that there is nothing limiting us to having a single tracking
      system, or even a single MotionStar driver. For example, we could create
      two MotionStar configurations in the same file, each with different
      network settings, each talking to a different physical MotionStar. The
      <property>Instance Name</property> at the top of the configuration
      window can be used to distinguish one from the other.</para>

      <section>
        <title>Create Position Proxies</title>

        <para>In VR Juggler, we generally do not interact with input devices
        directly. Instead, we create proxies for them. A Position Proxy
        represents a single positional input. It is used to provide a simple,
        generic interface to position data, abstracting away from the actual
        hardware.</para>

        <figure id="vjheadchunkfigure">
          <title>Editing a Position Proxy called &#34;VJHead&#34;. The proxy
          attaches to a device named &#34;MotionStar&#34; and applies a
          transformation and rotation to the device data.</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="figures/vjhead_chunk.png" format="PNG"
              scale="50" width="4in" />
            </imageobject>
          </mediaobject>
        </figure>

        <para>As mentioned previously, the MotionStar in our example setup has
        two sensors, so we will need to create two Position Proxies. Add two
        new Position Proxy configuration elements to your configuration.</para>

        <para>Now it is time to fill in the particular information for each
        Proxy. We can start with the instance names, calling one proxy
        &#34;VJHead&#34; and the other &#34;VJWand&#34;. VR Juggler
        applications use these proxy names to access input devices. These
        particular choices of names are a convention used by most VR Juggler
        applications. However, this naming convention is not a requirement.</para>

        <para>Each proxy has a pulldown menu where we can select the physical
        device it maps to - these will both refer to the MotionStar driver
        instance we have already configured. There is also a
        <property>Unit</property> option, which tells us which of the
        individual position inputs of the device to use. Our driver is
        configured for two sensors, so one of our proxies will be unit 0 and
        the other will be unit 1.</para>

        <para>The <property>Position Proxy</property> also has position
        transformation options (see below for a full description). These
        settings are used to transform the returned tracker information into a
        value that matches the correct physical coordinates to use. For
        example, in our particular example VR system, the physical tracking
        sensor that we are using as &#34;VJHead&#34; is mounted sideways on
        the earpiece of a pair of stereo glasses. The transformation settings
        we use (as seen in the screenshot) change that data so that the
        position returned to VR Juggler and the application itself is the
        position of a point directly between the user&#39;s eyes.</para>
      </section>

      <section>
        <title>Configuring position device coordinate transformations</title>

        <para>The positional information returned from a tracking system can
        be used directly, but many times the frame of reference for the
        trackers is not the same as the real world. Because of this, the
        tracking data needs to be transformed to be in the coordinate frame
        that the system (and user) expect for the data.</para>

        <para>This may sound complex, but it really just means that the
        coordinate system the tracking system is using is not the same as what
        VR Juggler applications expect. This is not because VR Juggler
        requires some certain coordinate system, the reason is that
        applications are generally written to expect the VR system to use a
        standard coordinate system. If your application had to run in two
        different systems and one system had the x-axis going the the right
        while the other had the x-axis going up, your application would be
        pretty confusing in one of the systems.</para>

        <para>Now that we all understand why tracking systems have to be
        configured we need to know how to do it. This section focuses on
        exactly this namely, &#34;how can I configure the transformations for
        my tracking system&#34;. Until recently, this was a little difficult
        to do with VR Juggler (ok it was downright painful). But recently we
        revamped the system so that all positional devices have a common way
        of configuring their transformations. We hope that this will make it
        easier to understand and create configurations.</para>

        <para>Before we get into the details though we need to take one side
        track into mathematics. Specifically matrix mathematics and notations.
        This is probably nothing you haven&#39;t seen before, we just need to
        agree on a starting point for this description.</para>

        <section>
          <title>Matrix notation</title>

          <para>This description is going to make use of a specific matrix
          notation for transformations between various frames of reference. We
          have found this notation very useful for tackling transformation
          problems related to VR. We didn&#39;t make up this notation or
          anything. The original inspiration came from a VR systems book, but
          we have adapted it slightly for our purposes. So here it is:</para>

          <para><subscript>frame1</subscript>M<subscript>frame2</subscript> -</para>

          <para>The notation uses subscripts to represent the two frames of
          reference for the transformation. In this case, we say that the
          matrix transforms from frame1 to frame2. More specifically it moves
          the frame of reference from frame1 to frame2. So if we are talking
          about transforming points (or other geometry) the transformation
          looks like:</para>

          <para>P<subscript>frame1</subscript> = <subscript>frame1</subscript>M<subscript>frame2</subscript>
          * P<subscript>frame2</subscript></para>

          <para>You can see that we are using the notation for points as well.
          The subscript of the point represents the frame of reference that
          the point&#39;s coordinates are relative too.</para>

          <para>We should mention that some readers may be saying to
          themselves now &#34;they have this thing backwards, this matrix
          moves from frame2 to frame1&#34;. This is true if you look at it
          from the perspective of the transformed points. But if you look at
          it from the perspective of transforming the frames of reference, the
          matrix moves from frame1 to frame2. It is all a matter of
          perspective. The math will work out the same either way, so think
          about it whichever way seems more comfortable.</para>

          <para>Where this notation gets interesting is what if we want to
          move from frame1 to frame3 and we have the following matrices:</para>

          <para><subscript>frame1</subscript>M<subscript>frame2</subscript>,
          <subscript>frame3</subscript>M<subscript>frame2</subscript></para>

          <para>We know that the matrix we want is <subscript>frame1</subscript>M<subscript>frame3</subscript>
          so the correct matrix is:</para>

          <para><subscript>frame1</subscript>M<subscript>frame3</subscript> =
          <subscript>frame1</subscript>M<subscript>frame2</subscript> *
          <subscript>frame2</subscript>M<subscript>frame3</subscript></para>

          <para>which means that I need to invert the<subscript> frame3</subscript>M<subscript>frame2</subscript>
          matrix that I have to use it.</para>

          <para>This notation makes things like this easy to &#34;see&#34;
          since the frames of reference are right there as part of the matrix
          name. We make use of this in the next section to keep track of which
          matrices to use at which times.</para>
        </section>

        <section>
          <title>Tracker transformations</title>

          <figure id="figure.tracker.config">
            <title>Frames of reference for configuring a tracking system</title>

            <mediaobject>
              <imageobject>
                <imagedata fileref="figures/config_trackers_diagram.png"
                format="PNG" scale="50" width="4in" />
              </imageobject>
            </mediaobject>
          </figure>

          <para>The figure above shows a generic view of the coordinate frames
          a work in a standard tracking system setup.</para>

          <para></para>

          <itemizedlist>
            <listitem>
              <para>World coordinate system: The world coordinate system is
              the base coordinates of the real world system. In other words
              this is the physical space that you are actually in when you are
              using the VR system. The coordinate system used depends upon
              your local preferences, but normally for VR Juggler systems axis
              are: X-right, Y-up, and Z-ou</para>
            </listitem>

            <listitem>
              <para>Tracker: The is the base frame of reference for the
              tracking system. This is normally defined by the &#34;base
              unit&#34; of the tracking system. For example with an ascension
              flock of bird tracking system this coordinate frame is defined
              by the location of the transmitter (the large black cube).</para>
            </listitem>

            <listitem>
              <para>Receiver: The is the coordinate system of the physical
              tracker (ex. a bird in a flock of birds). Normally people do not
              think of the reciever as having a coordinate system but instead
              think of it as having a position relative to the base tracker
              system. While this is true, that transformation actually defines
              another local coordinate frame for the receiver.</para>
            </listitem>

            <listitem>
              <para>Tracked Object: The tracked object frame is a general name
              for the actual location that you are trying to track. In some
              cases this is exactly the same as the Receiver, but it can be
              different. A common example of this is tracking the position of
              the user&#39;s eyes. Normally people do not put a reciever
              exactly at the position of the user&#39;s eyes (this would make
              it very hard to see the screen if you did). Instead, the
              receiver is normally mounted on the side of a pair of glasses or
              a hat or some other object that the user puts on their head. In
              this case the tracked object coordinate frame is at the location
              of the eyes.</para>
            </listitem>
          </itemizedlist>

          <para>When we configure a tracking system (and the associated
          positional proxies) we want to configure the system to return the
          correct tracked locations for the tracked objects in the
          environment. Computing this position involves the combination of
          multiple transformations. Just in the common case above, there are
          several transformations.<itemizedlist><listitem><para><subscript>world</subscript>M<subscript>tracker</subscript>:
          This is the transformation that captures the location of the tracker
          base system in the real world.</para></listitem><listitem><para><subscript>tracker</subscript>M<subscript>receiver</subscript>:
          This is the reported transformation of the receiver. This is the
          only transformation that normally varies as an application is
          running and is the value that is returned by the tracking system.</para></listitem><listitem><para><subscript>receiver</subscript>M<subscript>tracked_object</subscript>:
          This is the transformation from the position reported by the
          tracking system to the actual location that we want to track.</para></listitem></itemizedlist></para>

          <para>The value that the we want to configure the system to return
          is: <subscript>world</subscript>M<subscript>tracked_object</subscript></para>

          <para>This transformation is the location of the tracked object
          within the realworld. To return this value we must compute:</para>

          <para><subscript>world</subscript>M<subscript>tracked_object</subscript>
          = <subscript>world</subscript>M<subscript>tracker</subscript> *
          <subscript>tracker</subscript>M<subscript>receiver</subscript> *
          <subscript>receiver</subscript>M<subscript>tracked_objec</subscript>t</para>

          <para>VR Juggler takes care of computing this value at run-time, but
          as we have already said the position of the tracker within the
          tracking coordinate system (ie. <subscript>tracker</subscript>M<subscript>receiver</subscript>)
          is the only value that normally varies at run-time. The other two
          values must be configured in the tracking system setup. Lucky for
          you, we have made this very easy to do in VR Juggler and it actually
          sounds much more difficult then it is.</para>

          <para>Each object that can return position information within a VR
          Juggler system (ex: positional devices, positional proxies) can be
          configured with a set of Position Filters. The Position Filters are
          stored in an embeded list of filters within the position
          object&#39;s configuration element. So for example there is a
          Position Filter property in the MotionStart configuration element.
          The system is setup to allow multiple filters, but for now the only
          filter we are concerned about is called the &#34;Pos Xform
          Filter&#34;. This filter is used to add transformations to the
          positional object in a VR Juggler configuration. You can configure
          the filter to pre-multiply or post-multiply the returned positional
          value by a set transformation matrix. This is exactly what we need
          to configure a tracking system.</para>

          <para>We will start by configuring the tracking device. As we can
          see from the equation above, we need to pre-transform the value
          returned from the tracking system (<subscript>tracker</subscript>M<subscript>receiver</subscript>)
          by the position of the tracking system within the virtual world (<subscript>world</subscript>M<subscript>tracker</subscript>).
          We configure this by adding a Pos Xform Filter to the tracking
          device and setting the values of the pre-translation and
          pre-rotation to this value.</para>

          <para>To configure the tracked object positions, we need to
          configure the transformation applied to the position proxy for the
          tracked object (ex: the user head proxy). In this case though, the
          transformation we need to apply is a post-transform of the value.
          You just add a post-transformation Pos Xform Filter to the
          associated positional proxy and set the post-translation and
          post-rotation to the offset of the tracked object relative to the
          reciever being used to track the object.</para>

          <para>Once those two transformation values are configured, the
          tracking system should be setup and ready to run.</para>

          <para>In the best of all worlds, the above method would work
          flawlessly everytime. Unfortunately this doesn&#39;t always happen.
          So a couple of ideas to use when you run into trouble. First, we
          find that drawing a picture of the transformations within the system
          can frequently help. Just create a diagram that shows all the
          coordinate frames and the transformations between them. This can
          often help to find the one transformation that is not quite set
          correctly. Second, configure the system one step at a time.
          Don&#39;t try to get both the tracking system transformation and the
          proxy transformation set the first time. Instead, just work on
          getting the transformation correct for the tracking system. Once
          this value is set, you can start working on the proxy
          transformation. It is much easier to work on configuration a
          tracking system if only one value is changing at a time.</para>
        </section>
      </section>

      <section>
        <title>Creating Proxy Aliases (optional)</title>

        <para>Proxy Aliases provide a way to introduce multiple names for a
        single Proxy. A <property>Proxy Alias</property> element contains only
        two properties: its name and the name of the Proxy it points at.<footnote><para>In
        VR Juggler 2.0 Alpha 1, the <property>Proxy Alias</property> element
        actually contains an <property>AliasName</property> property in
        addition to the actual element name. This redundancy is likely to be
        removed in the future. For now, it is recommended that users always
        put the same string in the Alias element&#39;s <property>Name</property>
        and <property>AliasName</property>.</para></footnote></para>

        <para>The Proxy Alias provides a convenient way to reassign a
        commonly-used name like &#34;VJHead&#34; or &#34;VJButton0&#34; from
        one proxy to another. While not required, use of Proxy Aliases can
        make configuration files easier to modify and administrate.</para>
      </section>
    </section>

    <section>
      <title>Configure Other Input Devices</title>

      <para>In addition to moving around within an environment, users will
      also want to interact with the application in some way. There are many
      sorts of devices that can be used in a VR system. Wands and joysticks of
      various sorts are very popular. These are simple handheld devices,
      usually with a position tracking sensor attached to them and a number of
      buttons that the user can press to send commands to an application (such
      as &#34;fly forward&#34; or &#34;pick up the object I&#39;m
      touching&#34;). Gloves that sense the user&#39;s hand movements are also
      popular (see <xref linkend="PinchGloveSection" />, below, for an
      example). In surround-screen VR systems it is also possible to bring
      physical devices, such as a bicycle or the cab of a truck, into the VR
      system. In this case, the user can interact with the application by
      manipulating pedals, handlebars, or steering wheels.</para>

      <para>In VR Juggler, we divide most of these devices into digital or
      analog inputs. Digital devices are buttons similar to those found on a
      mouse or joystick and simply have on and off values. Analog devices
      return a range of data and can be used for steering wheels or foot
      pedals, among other things.</para>

      <para>Several tracking system manufacturers include handheld wand-style
      devices that can be used as a regular sensor in their hardware. For
      example, see <xref linkend="ISenseSection" /> at the end of this article
      for information about using digital inputs supplied by an InterSense
      tracking system.</para>

      <para>At VRAC, we have hooked up a large variety of custom devices via
      the IBox, a simple input device manufactured by Immersion Corp. The IBox
      connects to the serial port of a computer, and provides four digital
      inputs and four analog inputs. See <xref linkend="IBoxChunkFigure" />
      for an <property>IBox</property> element.</para>

      <figure id="IBoxChunkFigure">
        <title>Configuration for the Immersion Ibox.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures/ibox_chunk.png" format="PNG"
            scale="55" width="4in" />
          </imageobject>
        </mediaobject>
      </figure>

      <para>It is also possible to use simulated devices to achieve the same
      functionality. One of the wands in use at VRAC is in fact a wireless 2D
      mouse attached to a spare computer. We can configure VR Juggler
      applications to open a simulator input window on the spare computer
      (using an exported X Windows display) and map the wireless mouse&#39;s
      buttons to a simulated digital device. This is a fairly extreme example
      of the flexibility provided by VR Juggler&#39;s input system.</para>

      <section>
        <title>Creating Digital and Analog Proxies</title>

        <para>As with tracking devices, VR Juggler applications do not use
        input devices directly. Instead, proxies are used to provide a generic
        interface to each device. For each digital and analog input source in
        each of the devices, the configuration file should include a
        <property>Digital Proxy</property> or <property>Analog Proxy</property>
        configuration element.</para>

        <para>These two kinds of configuration elements are simpler than
        <property>Position Proxies</property> since they do not include the
        transformation properties needed for positional data. The only
        properties that must be filled in are the name of the device and the
        unit number. The unit number is used to distinguish between multiple
        analog or digital inputs available from a single device.</para>

        <para>Many VR Juggler applications (including the test and sample
        programs packaged with the VR Juggler source and binary distributions)
        expect there to be a set of digital inputs available with names of the
        form &#34;VJButton0&#34;, &#34;VJButton1&#34;, etc., which correspond
        to the buttons on a handheld wand.</para>

        <para>Fewer of the VR Juggler sample applications make use of analog
        devices, but when they do a similar naming convention (e.g.
        &#34;VJAnalog0&#34;) is used. Of course, nothing about these proxy
        names is hardcoded - the only requirement is that the config file
        provide the names that the particular application requests.</para>

        <para>As with Position Proxies, Digital and Analog Proxies can be
        given additional names with the use of <property>Proxy Alias</property>
        configuration elements.</para>
      </section>
    </section>

    <section>
      <title>Add User Configuration</title>

      <para>We have trackers in our configuration now, but how do we interpret
      the tracking data? Which sensor corresponds to the user&#39;s head, and
      which to his or her hands?</para>

      <para>We create a <property>User</property> configuration element to
      store a small amount of information about the person using our VR
      system. When we create displays later on, we&#39;ll tell each one which
      user to draw the view for.</para>

      <para>Typically, we will only need one <property>User</property>
      configuration element. It only has a few properties, as shown in the
      figure below.</para>

      <figure id="userchunkfigure">
        <title>A User configuration.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures/user_chunk.png" format="PNG"
            scale="60" width="4in" />
          </imageobject>
        </mediaobject>
      </figure>

      <para>The head position value in the User element is simply selected
      from a drop-down list of all the position proxies (and aliases) we have
      created.</para>

      <para>The eye separation value is used to create the separate left/right
      views that create a stereo display. It uses the same units as the rest
      of the VR Juggler coordinate system. The actual physical eye separation
      varies among individuals, though the value 0.229 (feet) will provide
      good results for most viewers.</para>
    </section>

    <section>
      <title>Add Displays</title>

      <para>Now that we have our input devices and users sorted out, we can
      finally think about the graphics. We need to create a display window for
      each of the four screens in our example system. We also need to provide
      some auxiliary information about the graphics pipes and X Windows
      displays on our system, as outlined below.</para>

      <section>
        <title>Create a DisplaySystem</title>

        <para>First, we need to create a new <guilabel>Display System</guilabel>
        element to support our displays.</para>

        <para>VR Juggler&#39;s display windows use the idea of pipe numbers -
        integer values associated with a particular X Windows display - to
        decide where to open. On a single display system like the average
        desktop computer, this is simple - the default X display is labeled
        &#34;:0.0&#34;.<footnote><para>The display names are ignored on
        Windows systems, but the number of pipes is still important.</para></footnote></para>

        <para>On a multi-pipe system, there are multiple displays, and in our
        example system the video output of each display is connected to a
        different monitor. The mapping is shown in the screenshot below (the
        value &#34;-1&#34; for a display is shorthand for using the value of
        the <envar>$DISPLAY</envar> environment variable.</para>

        <figure id="displaysystemchunkfigure">
          <title>DisplaySystem configuration.</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="figures/displaysystem_chunk.png"
              format="PNG" scale="60" width="4in" />
            </imageobject>
          </mediaobject>
        </figure>

        <para>In addition to the mapping provided by the <property>XPipes</property>
        property, the Display System also has a <property>Number of Pipes</property>
        property. This property is used for OpenGL-based VR Juggler
        applications to determine how many drawing threads to create. For
        <property>Number of Pipes</property> = n, VR Juggler will create n
        threads, each servicing one of the first n values in
        <property>XPipes</property>.</para>

        <para>Extra values in <property>XPipes</property> can be useful for
        defining X displays that are not used for graphics drawing, but which
        are used for other purposes - e.g. user input windows. See the
        description on Configuring simulated devices, below, for an example.</para>
      </section>

      <section>
        <title>Define Display Windows</title>

        <para>The next step - and the last needed to provide minimal
        functionality - is to create configuration elements for our display
        windows. To begin this step, we need some information about how the
        video is connected to our VR system. For this example there are four
        screens, each with a stereo display powered by a separate X Display on
        the host computer. We also need to determine where on the screen to
        position the window so that our graphics show up on the projectors.</para>

        <para>In VR Juggler 2.0, a single display window can contain multiple
        viewports. A Viewport is a rectangular area of the window that
        contains a particular graphic image. So, we could configure a window
        with separate viewports on the top and bottom halves of the window.
        There are various ways this feature can be used. For example, some
        HMDs and other stereo display devices will use the top half of the
        screen for one eye&#39;s view and the bottom half of the screen for
        the other eye. While we could achieve the same results by putting two
        windows on the same screen, using a single window with two viewports
        may provide better performance.</para>

        <para>With this information on hand, it is time to create the
        configuration elements for the display windows. Add a new
        <guilabel>Display Window</guilabel> element to the configuration.
        We&#39;ll start by editing this element and filling in information for
        the right wall of our surround-screen system, as shown in the figure.
        Most of the properties will be the same for each window.</para>

        <figure id="surfacedisplaychunkfigure">
          <title>Surface Display for the front screen.</title>

          <mediaobject>
            <imageobject>
              <imagedata fileref="figures/surfaceviewport_chunk.png"
              format="PNG" scale="60" width="4in" />
            </imageobject>
          </mediaobject>
        </figure>

        <para>Most of the properties in the <property>Display Window</property>
        element concern the actual placement and creation of the window on
        screen. In our system, the projector for the right wall is connected
        to the output of the X Display &#34;:1.0&#34; (pipe 1 according to our
        <property>Display System</property> element). The X display itself
        provides a 2304x1024 pixel display area, the rightmost 1024x1024
        region of which is sent to the projector. These numbers are all
        determined by the video settings and physical connections of the
        computer running the VR system.</para>

        <para>In <xref linkend="surfacedisplaychunkfigure" /> we have entered
        all of this data into the <property>Surface Display</property>
        element. The window position and size at the top of the window is easy
        to understand; the important thing to remember is that the position
        listed is the position of the window&#39;s lower-left-hand corner
        relative to the display&#39;s lower-left-corner. In this case the
        window is flush with the bottom of the display and shifted over 1284
        pixels. We place the window on pipe 0 (&#34;:0.0&#34;), and ask for a
        stereo view with none of the standard window border decorations.</para>

        <para>We set the <property>Active</property> property to true since we
        want our window to be opened automatically when VR Juggler starts up.
        We can set the <property>Borderless</property> to true or false as we
        prefer.</para>

        <para>The front wall of our example system is a 12&#39;x9&#39;
        projection screen positioned six feet in front of our origin. Its
        projector is connected to the output of the X Display &#34;:0.0&#34;
        (pipe 0 according to our <property>Display System</property> element).
        The X display itself provides a 2304x1024 pixel display area, the
        rightmost 1024x1024 region of which is sent to the projector. These
        numbers are all determined by the video settings and physical
        connections of the computer running the VR system.</para>

        <para>Next we need to provide the information that VR Juggler will use
        to render graphics to our window - we do this by adding a
        <property>Surface Viewport</property> to our window (seen on the right
        side of the figure). First we provide the position and size of the
        viewport within its window. This is similar to defining a window&#39;s
        position on screen - the origin is relative to the lower left - but
        the values used are proportions. Since we only have one viewport in
        this window, its origin is (0.0, 0.0) - the lower left corner - and
        its size is (1.0, 1.0) - it&#39;s as big as the window itself. As
        another example, if our viewport only filled the top half of the
        window, we&#39;d give it an origin of (0.0, 0.5) and a size of (1.0,
        0.5).</para>

        <para>The right wall of our example system is a 12&#39;x9&#39;
        projection screen positioned six to the right of our origin. The
        <property>Corners</property> property in the viewport configuration
        lists the positions of the screen&#39;s corners relative to the origin
        of the VR Juggler coordinate system. You will recall that we decided
        to use the center of the VR system&#39;s floor as our origin. Then,
        for example, the values for the right screen&#39;s upper-left-hand
        corner are: x = +6 (six feet to the right), y = +9 (nine feet up), and
        z = -6 (six feet forward, and negative because we use a right-handed
        coordinate system).</para>

        <para>VR Juggler also needs to know where the user is in order to set
        up the viewing parameters for the viewport - we set this by selecting
        our User element from a drop down list.</para>

        <para>For now, we leave the <property>Tracked</property> property
        false. The <property>Tracked</property> property is used for
        configuring displays for head-mounted displays (HMDs) and similar
        devices - we&#39;ll discuss its use later.</para>

        <para>There are three more displays to go, but these are easier.
        Select the RightScreen element in the tree view of the configuration
        file and press the <guibutton>Duplicate</guibutton> button.
        Double-click on the newly created &#34;copy of RightScreen&#34;
        element to edit its values. Rename it to &#34;LeftScreen&#34; and
        change the <property>Pipe</property> and <property>Corners</property>
        values appropriately.</para>

        <note>
          <para>Copy/Paste support has not yet been added to VRJConfig. Until
          that time, you will have to manually create a new configuration
          element and fill in the values.</para>
        </note>

        <para>Repeat the previous step to create configurations for the front
        screen and the floor.</para>
      </section>
    </section>

    <section>
      <title>Additional Features</title>

      <para>At this point, our example file has all the information needed to
      start up a simple, OpenGL-based VR Juggler application. If you&#39;ve
      been following along making a configuration file for your own VR system,
      you may want to give it a try with one of the sample programs in VR
      Juggler&#39;s samples directory.</para>

      <para>The next sections discuss configuration options for using other
      graphics APIs (primarily OpenGL Performer) and for enabling some of VR
      Juggler&#39;s advanced features, such as dynamic reconfiguration.</para>

      <section>
        <title>Configuring OpenGL Performer API Features</title>

        <para>VR Juggler includes a handful of configuration options
        specifically for applications that use the <trademark>OpenGL Performer</trademark>
        graphics API. To configure these features, add a new
        <property>Performer API</property> element to your configuration. This
        element lets you choose the model files (e.g. in &#34;.flt&#34;
        format) that should be used to represent the user&#39;s head and wand
        position in simulator mode. Example model files are provided in
        <filename>$VJ_BASE_DIR/share/vrjuggler/data/models</filename>.</para>
      </section>

      <section>
        <title>Configuring Audio Features</title>

        <para>There are also special configuration elements for configuring VR
        Juggler&#39;s built-in audio capabilities - one for the AudioWorks
        driver, and one for the SL sound driver. See <citetitle>Sonix: Juggler
        Simple Sound Interface</citetitle> for more information.</para>
      </section>

      <section>
        <title>Enabling Dynamic Reconfiguration</title>

        <note>
          <para>As of VR Juggler 2.0 Alpha 1, dynamic reconfiguration is not
          yet fully supported. Once the feature has been added, you will be
          able to dynamically reconfigure your application through a CORBA
          connection.</para>
        </note>
      </section>

      <section>
        <title>Logging Performance Data</title>

        <note>
          <para>As of VR Juggler 2.0 Alpha 1, peformance monitoring is not yet
          fully supported.</para>
        </note>
      </section>
    </section>
  </chapter>

  <chapter>
    <title>Configuring Other Hardware Devices</title>

    <para>Our step-by-step example above concentrated on a particular hardware
    setup. In the next several sections, we will discuss configuration for a
    number of other VR devices.</para>

    <section>
      <title>Desk or Wall-Based Projection Displays</title>

      <para>There are a large number of single-display projection systems with
      a variety of physical configurations - walls, desktops, angled surfaces,
      etc. All of these display devices can be configured using the same
      technique discussed above for configuring an SSVR system. Simply create
      a <property>Surface Display</property> element, and fill in the values
      for the screen/desk&#39;s corners relative to the origin of the VR
      Juggler coordinate system (the origin should typically be a spot on the
      floor several feet in front of the screen, or possibly directly below a
      horizontal desk-type display.</para>
    </section>

    <section>
      <title>Head-Mounted Displays</title>

      <para>There are a large class of head-mounted displays (HMDs), ranging
      from helmets to glasses to displays mounted on movable arms. These are
      also configured for use with VR Juggler with the <property>Surface
      Display</property> configuration element but there are two important
      differences.</para>

      <para>The most obvious difference is that these displays do not have a
      fixed position. Instead, they follow the movements of the user&#39;s
      head. To enable this sort of head tracking, turn on the
      <property>Tracked</property> property in the <property>Surface Display</property>.
      Next, select a position proxy for the <property>TrackerProxy</property>
      property (usually, you&#39;ll want to use VJHead for this). Now, the
      view drawn for this display will change as if it were hooked to a video
      camera on the user&#39;s head.</para>

      <para>The other difference with an HMD display is that the values for
      the <property>Corners</property> property typically won&#39;t be the
      physical position of the displays (typically a few inches in front of
      the user&#39;s face). Instead, the HMD documentation will give display
      information, such as &#34;108 inch diagonal at 4&#39; distance, 4x3
      aspect ratio&#34;. This information can be used to calculate reasonable
      values for the corners, with the origin at the point between the
      wearer&#39;s eyes. (For the above example, the corners values would be
      x= +/- 3.6 feet, y= +/- 2.7 feet, and z = -4.0 feet).</para>

      <para>One other aspect of HMD configuration to mention is that some HMDs
      use two separate video inputs, one channeled to each eye. If this is the
      case, each eye should be configured as a separate <property>Surface
      Display</property> window, with its screen coordinates and so forth. Set
      the <property>View</property> property to &#34;Left Eye&#34; or
      &#34;Right Eye&#34; in each, instead of &#34;Stereo&#34;. Consult your
      HMD documentation for more details.</para>
    </section>

    <section>
      <title>Using the <trademark>Trackd</trademark> Tracker Daemon with VR
      Juggler</title>

      <para>VRCO&#39;s <trademark>Trackd</trademark> is a standalone server
      (or &#34;daemon&#34;) which can manage a large variety of VR hardware
      devices and supply input data to end-user applications. VR Juggler can
      communicate with Trackd to provide input data for an application.</para>

      <para>Individual devices in Trackd are identified by
      <firstterm>shared memory keys</firstterm> - integer values that are
      defined in Trackd&#39;s own configuration files. Note that configuring
      Trackd itself is outside the scope of either VR Juggler or this
      document.</para>

      <figure id="TrackdChunks">
        <title>Configuration for the <trademark>Trackd</trademark> input
        device daemon.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures/trackd_chunks.png" format="PNG"
            scale="60" width="4in" />
          </imageobject>
        </mediaobject>
      </figure>

      <para>VR Juggler uses two kinds of configuration elements for
      communicating with Trackd:</para>

      <itemizedlist>
        <listitem>
          <para><property>TrackdSensor</property>, which is equivalent to a
          single positional input in VR Juggler. The only information you need
          to configure a TrackdSensor is its shared memory key (the
          transformation and other parameters shared by most positional input
          devices are handled by Trackd&#39;s own configuration). Once a
          sensor is configured, you should attach a Position Proxy to it, as
          was described for the MotionStar in the tutorial above.</para>
        </listitem>

        <listitem>
          <para><property>TrackdController</property>, which presents analog
          data in a specified range. In addition to the shared memory key, you
          must supply VR Juggler with the minimum and maximum values the
          analog controller can return.</para>
        </listitem>
      </itemizedlist>

      <para>A VR Juggler configuration can include multiple sensors and
      controllers depending only on the number of devices Trackd itself is
      configured to use.</para>
    </section>

    <section id="ISenseSection">
      <title>Using InterSense Trackers</title>

      <para>VR Juggler includes a driver for the InterSense IS-900 wireless
      tracking system. This tracking system supports multiple
      &#34;stations&#34;, each of which provides a positional input. Some
      stations also include digital and analog inputs - buttons, sliders, etc.</para>

      <figure id="ISenseChunkFigure">
        <title>Configuration for InterSense tracking system.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures/isense_chunk.png" format="PNG"
            scale="45" width="5in" />
          </imageobject>
        </mediaobject>
      </figure>

      <para>The first step in configuring this kind of tracker is to create an
      <property>Intersense</property> configuratiorn element. It has many of
      the same fields as every other tracker configuration, such as serial
      port information and translation/rotation values (see <xref
      linkend="BasicTrackerConfig" />, above).</para>

      <para>The most interesting variation in the InterSense driver
      configuration is the <property>Stations</property> property. This
      property contains multiple <property>Station</property> configuration
      elements, one for each physical station connected to the InterSense
      tracking system as seen in <xref linkend="ISenseChunkFigure" />.</para>

      <para>Each station has an integer ID value (which is determined by the
      order in which it is hooked up to the InterSense system). Since every
      station provides positional/rotational data, the Intersense driver as a
      whole provides as many unique positional inputs as it has stations. When
      you attach Position Proxies to the InterSense driver, the unit number in
      the proxy corresponds to the ID of one of the stations.</para>

      <para>The stations may also provide digital and analog data. If the
      <property>Use Digital</property> property in a station is set to true,
      VR Juggler&#39;s InterSense driver will provide its digital data to
      applications. The <property>Digital First</property> and
      <property>Digital Count</property> properties determine how a
      station&#39;s digital inputs are mapped to unit numbers that can be used
      to attach Digital Proxies to the InterSense driver. For example, if the
      <property>Digital First</property> property for a particular station is
      3, and the <property>Digital Count</property> is 4, the Digital Proxies
      with units of 3, 4, 5, and 6 will provide inputs from this station.
      Values for analog inputs are specified similarly.</para>

      <para>VRJConfig does not check for conflicts between stations.
      Therefore, you should be careful that you do not specify two stations as
      providing the same digital or analog data unit.</para>
    </section>

    <section id="PinchGloveSection">
      <title>Using Fakespace <trademark>Pinch</trademark> Gloves</title>

      <para>VR Juggler includes a driver for the <trademark>Pinch</trademark>
      Gloves marketed by Fakespace Labs. Pinch Gloves (available singly or in
      pairs) have sensors on the fingertips which determine if each finger is
      touching either the palm of the hand or another finger. The result is a
      set of binary values, five for each hand.</para>

      <para>Configuration of the Pinch Glove driver itself is simple. The
      glove hardware attaches to the serial port of the host computer, so the
      configuration element includes serial port and baud rate properties.
      Most users attach some kind of a tracking sensor to the gloves, so VR
      Juggler&#39;s configuration provides a property for specifying a
      Position Proxy attached to the glove.</para>

      <para>Every VR Juggler input device needs to be attached to a proxy so
      that it can be accessed by applications. For the Pinch Gloves there are
      two choices. First, the glove can be treated as a digital input source
      with five boolean values (10 for a pair). This means that you can attach
      five Digital Proxies to a Pinch Glove (with unit properties in the range
      0 to 5), and use it to emulate a wand.</para>

      <para>The other alternative is to attach a Glove Proxy to it.
      Applications that use the Glove Proxy interface can receive information
      about the individual finger joint positions of the glove. Of course,
      because of the capabilities of the Pinch Glove, VR Juggler simply infers
      these joint positions based on the boolean values for each finger.</para>
    </section>
  </chapter>

  <chapter>
    <title>Configuring Simulated Devices</title>

    <para>While the focus of VR Juggler development is on fully immersive VR
    systems, the reality is that many times such a system is not available.
    Often, this is because many developers have to share a single HMD or other
    device. Researchers also frequently need to demonstrate their applications
    in a wide range of settings, where the usual paraphernalia of VR is
    unavailable.</para>

    <para>For all these reasons, VR Juggler supports a set of software devices
    that simulate real positional, analog, and digital input devices. By
    configuring these simulated devices, users can interact with an
    application using only a keyboard and mouse.</para>

    <section>
      <title>Creating a Keyboard Input Window</title>

      <para>VR Juggler uses keyboard input windows as the source for all
      simulator data. In order to use simulated devices, a configuration file
      needs to contain at least one <property>Keyboard</property>
      configuration element. It may be convenient to use multiple keyboard
      windows if you are trying to simulate a large number of devices - that
      way each device can be controlled with the same key bindings, but with a
      different keyboard window being active.</para>

      <para>The <citetitle>VR Juggler Getting Started Guide</citetitle> gives
      an example of running an application with simulated devices and using
      the keyboard window to control the user&#39;s position and wand buttons.</para>

      <para>The <property>Keyboard</property> configuration element is
      relatively simple. Its most important properties are simply the size and
      position of the window to open. It also has a <property>Display Number</property>
      property which, like the <property>Pipe</property> property in
      <property>Surface Displays</property> (described above), refers to one
      of the displays named in the <property>Display System</property>
      element. Usually, that property is set to &#34;-1&#34;.</para>

      <para>The <property>Keyboard</property> element has a few more esoteric
      properties:</para>

      <itemizedlist>
        <listitem>
          <para>Simulated devices can use mouse movement in addition to
          keypresses for their controls. The <property>Mouse Sensitivity</property>
          property controls how mouse movements are translated into
          keypresses. The value is the number of keypresses that a single
          pixel of mouse movement should be translated into. For example, 0.1
          would mean ten pixels of mouse movement translate into a single
          keypress. Higher values increase sensitivity. 1.0 is a reasonable
          initial choice, which can be customized to match the user&#39;s
          tastes.</para>
        </listitem>

        <listitem>
          <para>The <property>Lock Key</property> property is used to set a
          key which, when held down, will &#34;lock&#34; the mouse in place in
          the center of the input window. This feature is useful in
          environments such as X Windows where moving the mouse out of a
          window changes the input focus. The <property>Start Locked</property>
          property is self-explanatory, though its use may seem rather odd. It
          is generally used when opening a window on a separate display - such
          as one with a wireless mouse attached, as was described in the
          section on input devices, above.</para>
        </listitem>

        <listitem>
          <para>The <property>Sleep Time</property> property controls the
          behavior of the control thread that manages the keyboard window. It
          should generally be set to a value between 10 and 50.</para>
        </listitem>
      </itemizedlist>

      <para>As with every other VR Juggler input device, in order to use a
      keyboard window you must create a proxy for it. The
      <property>Keyboard Proxy</property> element is very trivial, consisting
      only of the <property>Keyboard</property> element&#39;s name.</para>

      <para>Note that in VR Juggler 2.0, display windows will also be able to
      serve double duty as keyboard input sources.</para>
    </section>

    <section>
      <title>Creating Simulated Devices</title>

      <para>There are simulator devices for each kind of input device VR
      Juggler recognizes.</para>

      <figure id="SimDevChunkFigure">
        <title>Configuration of simulated devices. These are the digital and
        positional simulators used to provide the user&#39;s head control and
        wand buttons in the simstandalone.config file included in the VR
        Juggler distribution.</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="figures/simdevice_chunk.png" format="PNG"
            scale="40" />
          </imageobject>
        </mediaobject>
      </figure>

      <para>All simulator devices have a few commonalities. Each is configured
      with the name of a <property>Keyboard Proxy</property> which it uses as
      a source of user input. Also, each has a set of key bindings. For
      example, a position simulator will have keystrokes assigned for movement
      in each direction. By comparison, a digital simulator will have a single
      keystroke to indicate &#34;on&#34;, and an analog simulator will have a
      pair of keystrokes to increase and decrease its value. The configuration
      elements for digital and analog simulators can actually configure
      multiple instances of each, just by creating additional keystrokes. Some
      sample simulator configuration elements are shown in <xref
      linkend="SimDevChunkFigure" />. Note how the digital simulator on the
      right simulates 8 separate digital values, using a combination of mouse
      buttons and number keys.</para>

      <para>Just like every other input device, simulator devices must be
      connected to proxies before they can be used by VR Juggler. Simulated
      devices use the exact same proxy elements as real hardware devices and
      the proxies are configured with the same combination of (simulated)
      device name and unit number. Note that position simulators (as well as
      the glove simulator objects) only supply one set of input data, so the
      <property>Unit</property> property for any proxy referring to them
      should be 0. Digital and analog simulators, on the other hand, can be
      configured to support an arbitrary number of input device units.</para>
    </section>
  </chapter>
</book>
